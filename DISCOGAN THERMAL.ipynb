{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "#from data_loader import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import scipy\n",
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def step_decay(epoch):\n",
    "    \n",
    "    \n",
    "    initial_lrate=0.1\n",
    "    drop=0.6\n",
    "    epochs_drop = 3.0\n",
    "    lrate= initial_lrate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "   \n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [ lrate]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 512\n",
    "img_cols = 512\n",
    "channels = 3\n",
    "img_shape = (img_rows, img_cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_res=(512, 512)\n",
    "dataset_name = 'PIX'\n",
    "img_res = img_res\n",
    "image_size = 512\n",
    "img_rows = 512\n",
    "img_cols = 512\n",
    "channels = 3\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "patch = int(img_rows / 2**4)\n",
    "disc_patch = (patch, patch, 1)\n",
    "disc_loss =[]\n",
    "gen_loss = []\n",
    "# Number of filters in the first layer of G and D\n",
    "gf = 128\n",
    "df = 128\n",
    "optimizer = Adam(0.0001, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data( batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"test\"\n",
    "        path = glob('./datasets/%s/%s/*' % (dataset_name, data_type))\n",
    "        batch_size=3\n",
    "        if batch_size > 0:\n",
    "            batch_images = np.random.choice(path, size=batch_size)\n",
    "        else:\n",
    "            batch_images = np.array([])\n",
    "        #batch_images = np.random.choice(path, size=batch_size)\n",
    "\n",
    "        imgs_A = []\n",
    "        imgs_B = []\n",
    "        for img_path in batch_images:\n",
    "            img = imread(img_path)\n",
    "\n",
    "            h, w, _ = img.shape\n",
    "            _w = int(w/2)\n",
    "            img_A, img_B = img[:, :_w, :], img[:, _w:, :]\n",
    "\n",
    "            img_A = scipy.misc.imresize(img_A, img_res)\n",
    "            img_B = scipy.misc.imresize(img_B, img_res)\n",
    "\n",
    "            # If training => do random flip\n",
    "            if not is_testing and np.random.random() < 0.5:\n",
    "                img_A = np.fliplr(img_A)\n",
    "                img_B = np.fliplr(img_B)\n",
    "\n",
    "            imgs_A.append(img_A)\n",
    "            imgs_B.append(img_B)\n",
    "\n",
    "        imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "        imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "        return imgs_A, imgs_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"val\"\n",
    "        path = glob('./datasets/%s/%s/*' % (dataset_name, data_type))\n",
    "        batch_size=3\n",
    "        n_batches = int(len(path) / batch_size)\n",
    "\n",
    "        for i in range(n_batches-1):\n",
    "            batch = path[i*batch_size:(i+1)*batch_size]\n",
    "            imgs_A, imgs_B = [], []\n",
    "            for img in batch:\n",
    "                img = imread(img)\n",
    "                h, w, _ = img.shape\n",
    "                half_w = int(w/2)\n",
    "                img_A = img[:, :half_w, :]\n",
    "                img_B = img[:, half_w:, :]\n",
    "\n",
    "                img_A = scipy.misc.imresize(img_A, img_res)\n",
    "                img_B = scipy.misc.imresize(img_B, img_res)\n",
    "\n",
    "                if not is_testing and np.random.random() > 0.5:\n",
    "                        img_A = np.fliplr(img_A)\n",
    "                        img_B = np.fliplr(img_B)\n",
    "\n",
    "                imgs_A.append(img_A)\n",
    "                imgs_B.append(img_B)\n",
    "\n",
    "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "            yield imgs_A, imgs_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_batch(batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"val\"\n",
    "        path = glob('./datasets/%s/%s/*' % (dataset_name, data_type))\n",
    "        batch_size=3\n",
    "        m_batches = int(len(path) / batch_size)\n",
    "        return m_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(path):\n",
    "        return scipy.misc.imread(path, mode='RGB').astype(np.float)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(datadir):\n",
    "    #datadir = args.data\n",
    "    # assume each image is 512x256 split to left and right\n",
    "    imgs = glob.glob(os.path.join(datadir, '*.jpg'))\n",
    "    data_X = np.zeros((len(imgs),3,img_cols,img_rows))\n",
    "    data_Y = np.zeros((len(imgs),3,img_cols,img_rows))\t\n",
    "    i = 0\n",
    "    for file in imgs:\n",
    "        img = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (img_cols*2, img_rows)) \n",
    "        #print('{} {},{}'.format(i,np.shape(img)[0],np.shape(img)[1]))\n",
    "        img = np.swapaxes(img,0,2)\n",
    "\n",
    "        X, Y = split_input(img)\n",
    "\n",
    "        data_X[i,:,:,:] = X\n",
    "        data_Y[i,:,:,:] = Y\n",
    "        i = i+1\n",
    "    return data_X, data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = 64\n",
    "df = 64\n",
    "\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "img_A = Input(shape=img_shape)\n",
    "img_B = Input(shape=img_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " def d_layer(layer_input, filters, f_size=4, normalization=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if normalization:\n",
    "                d = InstanceNormalization()(d)\n",
    "            return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = InstanceNormalization()(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        \n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, gf, bn=False)\n",
    "        d2 = conv2d(d1, gf*2)\n",
    "        d3 = conv2d(d2, gf*4)\n",
    "        d4 = conv2d(d3, gf*8)\n",
    "        d5 = conv2d(d4, gf*8)\n",
    "        d6 = conv2d(d5, gf*8)\n",
    "        d7 = conv2d(d6, gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d7, d6, gf*8)\n",
    "        u2 = deconv2d(u1, d5, gf*8)\n",
    "        u3 = deconv2d(u2, d4, gf*8)\n",
    "        u4 = deconv2d(u3, d3, gf*4)\n",
    "        u5 = deconv2d(u4, d2, gf*2)\n",
    "        u6 = deconv2d(u5, d1, gf)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        #noise = Input(shape=img_shape)\n",
    "        output_img = Conv2D(channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "\n",
    "        return Model(d0, output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator1():\n",
    "\n",
    "        d0 = Input(shape=img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, gf, normalize=False)\n",
    "        d2 = conv2d(d1, gf*2)\n",
    "        d3 = conv2d(d2, gf*4)\n",
    "        d4 = conv2d(d3, gf*8)\n",
    "        d5 = conv2d(d4, gf*8)\n",
    "        d6 = conv2d(d5, gf*8)\n",
    "        d7 = conv2d(d6, gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d7, d6, gf*8)\n",
    "        u2 = deconv2d(u1, d5, gf*8)\n",
    "        u3 = deconv2d(u2, d4, gf*8)\n",
    "        u4 = deconv2d(u3, d3, gf*4)\n",
    "        u5 = deconv2d(u4, d2, gf*2)\n",
    "        u6 = deconv2d(u5, d1, gf)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(channels, kernel_size=4, strides=1,\n",
    "                            padding='same', activation='tanh')(u7)\n",
    "\n",
    "        return Model(d0, output_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "\n",
    "        \n",
    "\n",
    "        img = Input(shape=img_shape)\n",
    "\n",
    "        d1 = d_layer(img, df, normalization=False)\n",
    "        d2 = d_layer(d1, df*2)\n",
    "        d3 = d_layer(d2, df*4)\n",
    "        d4 = d_layer(d3, df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_A = build_discriminator()\n",
    "d_B = build_discriminator()\n",
    "d_A.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "d_B.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_AB = build_generator()\n",
    "g_BA = build_generator()\n",
    "# Translate images to the other domain\n",
    "fake_B = g_AB(img_A)\n",
    "fake_A = g_BA(img_B)\n",
    "# Translate images back to original domain\n",
    "reconstr_A = g_BA(fake_B)\n",
    "reconstr_B = g_AB(fake_A)\n",
    "\n",
    "# For the combined model we will only train the generators\n",
    "d_A.trainable = False\n",
    "d_B.trainable = False\n",
    "# Discriminators determines validity of translated images\n",
    "valid_A = d_A(fake_A)\n",
    "valid_B = d_B(fake_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = Model(inputs=[img_A, img_B],\n",
    "                              outputs=[ valid_A, valid_B,\n",
    "                                        fake_B, fake_A,\n",
    "                                        reconstr_A, reconstr_B ])\n",
    "combined.compile(loss=['mse', 'mse',\n",
    "                                    'mae', 'mae',\n",
    "                                    'mae', 'mae'],\n",
    "optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_imageGA(X, rows=1):\n",
    "    assert X.shape[0]%rows == 0\n",
    "    int_X = ((X*127.5+127.5).clip(0,255).astype('uint8'))\n",
    "    int_X = int_X.reshape(-1,image_size,image_size, 3)\n",
    "    int_X = int_X.reshape(rows, -1, image_size, image_size,3).swapaxes(1,2).reshape(rows*image_size,-1, 3)\n",
    "    pil_X = Image.fromarray(int_X)\n",
    "    t = str(round(time.time()))\n",
    "    os.makedirs('./images12/genA',  exist_ok=True)\n",
    "    pil_X.save(\"./images12/\"+'genA/'+ t + \".png\", 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_imageGB(X, rows=1):\n",
    "    assert X.shape[0]%rows == 0\n",
    "    int_X = ((X*127.5+127.5).clip(0,255).astype('uint8'))\n",
    "    int_X = int_X.reshape(-1,image_size,image_size, 3)\n",
    "    int_X = int_X.reshape(rows, -1, image_size, image_size,3).swapaxes(1,2).reshape(rows*image_size,-1, 3)\n",
    "    pil_X = Image.fromarray(int_X)\n",
    "    t = str(round(time.time()))\n",
    "    os.makedirs('./images12/genB',  exist_ok=True)\n",
    "    pil_X.save(\"./images12/\"+'genB/'+ t + \".png\", 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_imageOA(X, rows=1):\n",
    "    assert X.shape[0]%rows == 0\n",
    "    int_X = ((X*127.5+127.5).clip(0,255).astype('uint8'))\n",
    "    int_X = int_X.reshape(-1,image_size,image_size, 3)\n",
    "    int_X = int_X.reshape(rows, -1, image_size, image_size,3).swapaxes(1,2).reshape(rows*image_size,-1, 3)\n",
    "    pil_X = Image.fromarray(int_X)\n",
    "    t = str(round(time.time()))\n",
    "    os.makedirs('./images12/oriA',  exist_ok=True)\n",
    "    pil_X.save(\"./images12/\"+'oriA/'+ t + \".png\", 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_imageOB(X, rows=1):\n",
    "    assert X.shape[0]%rows == 0\n",
    "    int_X = ((X*127.5+127.5).clip(0,255).astype('uint8'))\n",
    "    int_X = int_X.reshape(-1,image_size,image_size, 3)\n",
    "    int_X = int_X.reshape(rows, -1, image_size, image_size,3).swapaxes(1,2).reshape(rows*image_size,-1, 3)\n",
    "    pil_X = Image.fromarray(int_X)\n",
    "    t = str(round(time.time()))\n",
    "    os.makedirs('./images12/oriB',  exist_ok=True)\n",
    "    pil_X.save(\"./images12/\"+'oriB/'+ t + \".png\", 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_imageRB(X, rows=1):\n",
    "    assert X.shape[0]%rows == 0\n",
    "    int_X = ((X*127.5+127.5).clip(0,255).astype('uint8'))\n",
    "    int_X = int_X.reshape(-1,image_size,image_size, 3)\n",
    "    int_X = int_X.reshape(rows, -1, image_size, image_size,3).swapaxes(1,2).reshape(rows*image_size,-1, 3)\n",
    "    pil_X = Image.fromarray(int_X)\n",
    "    t = str(round(time.time()))\n",
    "    os.makedirs('./images12/RB',  exist_ok=True)\n",
    "    pil_X.save(\"./images12/\"+'RB/'+ t + \".png\", 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_imageRA(X, rows=1):\n",
    "    assert X.shape[0]%rows == 0\n",
    "    int_X = ((X*127.5+127.5).clip(0,255).astype('uint8'))\n",
    "    int_X = int_X.reshape(-1,image_size,image_size, 3)\n",
    "    int_X = int_X.reshape(rows, -1, image_size, image_size,3).swapaxes(1,2).reshape(rows*image_size,-1, 3)\n",
    "    pil_X = Image.fromarray(int_X)\n",
    "    t = str(round(time.time()))\n",
    "    os.makedirs('./images12/RA',  exist_ok=True)\n",
    "    pil_X.save(\"./images12/\"+'RA/'+ t + \".png\", 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def sample_images( epoch, batch_i):\n",
    "        os.makedirs('images/%s' % dataset_name, exist_ok=True)\n",
    "        r, c = 3, 3\n",
    "        batch_size=2\n",
    "        imgs_A, imgs_B = load_data(batch_size=2, is_testing=True)\n",
    "\n",
    "        # Translate images to the other domain\n",
    "        fake_B = g_AB.predict(imgs_A)\n",
    "        fake_A = g_BA.predict(imgs_B)\n",
    "        # Translate back to original domain\n",
    "        reconstr_A = g_BA.predict(fake_B)\n",
    "        reconstr_B = g_AB.predict(fake_A)\n",
    "        display_imageGA(fake_B)\n",
    "        display_imageOA(imgs_A)\n",
    "        display_imageGB(fake_A)\n",
    "        display_imageOB(imgs_B)\n",
    "        display_imageRA(reconstr_A)\n",
    "        display_imageRB(reconstr_B)\n",
    "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[j,i].set_title(titles[j])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images12/%s/%d_%d.png\" % (dataset_name, epoch, batch_i))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images2(epoch, batch_i):\n",
    "        os.makedirs('images/%s' % dataset_name, exist_ok=True)\n",
    "        r, c = 3, 3\n",
    "        batch_size=2\n",
    "        imgs_A, imgs_B = load_data(batch_size=2, is_testing=True)\n",
    "        fake_A = generator.predict(imgs_B)\n",
    "        #print(imgs_A.shape)\n",
    "        display_imageG(fake_A)\n",
    "        display_imageO(imgs_A)\n",
    "        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Condition', 'Generated', 'Original']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i].set_title(titles[i])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%s/%d_%d.png\" % (dataset_name, epoch, batch_i))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + disc_patch)\n",
    "        fake = np.zeros((batch_size,) + disc_patch)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(load_batch(batch_size)):\n",
    "\n",
    "                # ----------------------\n",
    "                #  Train Discriminators\n",
    "                # ----------------------\n",
    "\n",
    "                # Translate images to opposite domain\n",
    "                fake_B = g_AB.predict(imgs_A)\n",
    "                fake_A = g_BA.predict(imgs_B)\n",
    "\n",
    "                # Train the discriminators (original images = real / translated = Fake)\n",
    "                dA_loss_real = d_A.train_on_batch(imgs_A, valid)\n",
    "                dA_loss_fake = d_A.train_on_batch(fake_A, fake)\n",
    "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "\n",
    "                dB_loss_real = d_B.train_on_batch(imgs_B, valid)\n",
    "                dB_loss_fake = d_B.train_on_batch(fake_B, fake)\n",
    "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "\n",
    "                # Total disciminator loss\n",
    "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "\n",
    "                # ------------------\n",
    "                #  Train Generators\n",
    "                # ------------------\n",
    "\n",
    "                # Train the generators\n",
    "                g_loss = combined.train_on_batch([imgs_A, imgs_B], [valid, valid, \\\n",
    "                                                                         imgs_B, imgs_A, \\\n",
    "                                                                         imgs_A, imgs_B])\n",
    "\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "                # Plot the progress\n",
    "                print (\"[%d] [%d] time: %s, [d_loss: %f, g_loss: %f]\" % (epoch, batch_i,\n",
    "                                                                        elapsed_time,\n",
    "                                                                        d_loss[0], g_loss[0]))\n",
    "                d_A.save_weights('./DISCO/weights/d_a_weights2222.h5', True)\n",
    "                d_B.save_weights('./DISCO/weights/d_b_weights2222.h5', True)\n",
    "                g_AB.save_weights('./DISCO/weights/G_a_weights2222.h5', True)\n",
    "                g_BA.save_weights('./DISCO/weights/G_b_weights2222.h5', True)\n",
    "                combined.save_weights('./DISCO/weights/combined_weights2222.h5', True)\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    sample_images(epoch, batch_i)\n",
    "                    #display_activation(activations, 16, 16, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvbl/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/home/cvbl/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "/home/cvbl/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "/home/cvbl/anaconda3/envs/keras/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [0] time: 0:00:27.453353, [d_loss: 28.286407, g_loss: 62.168594]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvbl/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "/home/cvbl/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [1] time: 0:00:40.985033, [d_loss: 75.161606, g_loss: 91.167534]\n",
      "[0] [2] time: 0:00:44.837357, [d_loss: 80.917084, g_loss: 7.415566]\n",
      "[0] [3] time: 0:00:48.496716, [d_loss: 3.361418, g_loss: 9.549139]\n",
      "[0] [4] time: 0:00:52.270981, [d_loss: 2.182079, g_loss: 6.944371]\n",
      "[0] [5] time: 0:00:55.861799, [d_loss: 0.799877, g_loss: 4.638917]\n",
      "[0] [6] time: 0:00:59.621080, [d_loss: 0.271640, g_loss: 3.931218]\n",
      "[0] [7] time: 0:01:03.426982, [d_loss: 0.562211, g_loss: 4.219603]\n",
      "[0] [8] time: 0:01:07.063661, [d_loss: 0.414094, g_loss: 3.701848]\n",
      "[0] [9] time: 0:01:11.525025, [d_loss: 0.289803, g_loss: 3.499085]\n",
      "[0] [10] time: 0:01:15.026316, [d_loss: 0.204118, g_loss: 3.362239]\n",
      "[0] [11] time: 0:01:18.690816, [d_loss: 0.189948, g_loss: 3.384554]\n",
      "[0] [12] time: 0:01:22.297892, [d_loss: 0.291650, g_loss: 3.753653]\n",
      "[0] [13] time: 0:01:26.117904, [d_loss: 0.175308, g_loss: 3.382652]\n",
      "[0] [14] time: 0:01:29.943931, [d_loss: 0.391886, g_loss: 3.507589]\n",
      "[0] [15] time: 0:01:33.480429, [d_loss: 0.194397, g_loss: 3.277776]\n",
      "[0] [16] time: 0:01:37.169317, [d_loss: 0.195667, g_loss: 2.792566]\n",
      "[0] [17] time: 0:01:40.638639, [d_loss: 0.188197, g_loss: 3.972323]\n",
      "[0] [18] time: 0:01:45.725860, [d_loss: 0.171911, g_loss: 3.717466]\n",
      "[0] [19] time: 0:01:49.115079, [d_loss: 0.186891, g_loss: 3.690126]\n",
      "[0] [20] time: 0:01:53.344573, [d_loss: 0.254642, g_loss: 2.956169]\n",
      "[0] [21] time: 0:01:57.039298, [d_loss: 0.258533, g_loss: 3.165014]\n",
      "[0] [22] time: 0:02:00.676960, [d_loss: 0.253962, g_loss: 4.468772]\n",
      "[0] [23] time: 0:02:04.396995, [d_loss: 0.799807, g_loss: 3.375866]\n",
      "[0] [24] time: 0:02:07.789153, [d_loss: 0.452667, g_loss: 2.900954]\n",
      "[0] [25] time: 0:02:11.459792, [d_loss: 0.287830, g_loss: 3.863208]\n",
      "[0] [26] time: 0:02:15.224874, [d_loss: 0.218475, g_loss: 3.418659]\n",
      "[0] [27] time: 0:02:19.650355, [d_loss: 0.222858, g_loss: 3.723467]\n",
      "[0] [28] time: 0:02:23.545718, [d_loss: 0.220698, g_loss: 2.621490]\n",
      "[0] [29] time: 0:02:27.532695, [d_loss: 0.240914, g_loss: 2.676087]\n",
      "[0] [30] time: 0:02:31.258342, [d_loss: 0.266405, g_loss: 4.296125]\n",
      "[0] [31] time: 0:02:34.708998, [d_loss: 0.340889, g_loss: 3.337246]\n",
      "[0] [32] time: 0:02:38.418973, [d_loss: 0.174348, g_loss: 3.326715]\n",
      "[0] [33] time: 0:02:42.268315, [d_loss: 0.204565, g_loss: 2.676699]\n",
      "[0] [34] time: 0:02:46.005487, [d_loss: 0.173440, g_loss: 2.853631]\n",
      "[0] [35] time: 0:02:49.886247, [d_loss: 0.301521, g_loss: 3.440467]\n",
      "[0] [36] time: 0:02:54.004924, [d_loss: 0.288057, g_loss: 2.672630]\n",
      "[0] [37] time: 0:02:57.578931, [d_loss: 0.246083, g_loss: 4.135965]\n",
      "[0] [38] time: 0:03:01.281615, [d_loss: 0.588984, g_loss: 2.754500]\n",
      "[0] [39] time: 0:03:05.278734, [d_loss: 0.473849, g_loss: 2.149004]\n",
      "[0] [40] time: 0:03:08.925445, [d_loss: 0.303951, g_loss: 2.420968]\n",
      "[0] [41] time: 0:03:12.572850, [d_loss: 0.134348, g_loss: 3.751731]\n",
      "[0] [42] time: 0:03:16.425796, [d_loss: 0.518593, g_loss: 3.012055]\n",
      "[0] [43] time: 0:03:20.528278, [d_loss: 0.435359, g_loss: 3.594625]\n",
      "[0] [44] time: 0:03:24.788227, [d_loss: 0.608874, g_loss: 2.448255]\n",
      "[0] [45] time: 0:03:28.492319, [d_loss: 0.480940, g_loss: 2.842672]\n",
      "[0] [46] time: 0:03:32.219965, [d_loss: 0.381546, g_loss: 3.207468]\n",
      "[0] [47] time: 0:03:36.041270, [d_loss: 0.410764, g_loss: 2.963775]\n",
      "[0] [48] time: 0:03:39.996802, [d_loss: 0.212018, g_loss: 3.227988]\n",
      "[0] [49] time: 0:03:44.078698, [d_loss: 0.247203, g_loss: 2.718876]\n",
      "[0] [50] time: 0:03:47.716748, [d_loss: 0.484852, g_loss: 3.202586]\n",
      "[0] [51] time: 0:03:51.377614, [d_loss: 0.520233, g_loss: 2.402937]\n",
      "[0] [52] time: 0:03:55.151514, [d_loss: 0.381275, g_loss: 2.956455]\n",
      "[0] [53] time: 0:03:59.086940, [d_loss: 0.315606, g_loss: 3.941334]\n",
      "[0] [54] time: 0:04:03.075944, [d_loss: 0.572579, g_loss: 3.340927]\n",
      "[0] [55] time: 0:04:06.942839, [d_loss: 0.662551, g_loss: 2.980760]\n",
      "[0] [56] time: 0:04:10.880352, [d_loss: 0.639756, g_loss: 2.892935]\n",
      "[0] [57] time: 0:04:14.732885, [d_loss: 0.463692, g_loss: 2.995746]\n",
      "[0] [58] time: 0:04:18.435679, [d_loss: 0.556173, g_loss: 2.864611]\n",
      "[0] [59] time: 0:04:22.158910, [d_loss: 0.549934, g_loss: 2.765620]\n",
      "[0] [60] time: 0:04:26.184677, [d_loss: 0.549368, g_loss: 2.338920]\n",
      "[0] [61] time: 0:04:29.860714, [d_loss: 0.427324, g_loss: 2.177988]\n",
      "[0] [62] time: 0:04:33.932516, [d_loss: 0.807357, g_loss: 3.342864]\n",
      "[0] [63] time: 0:04:37.839673, [d_loss: 3.063315, g_loss: 3.165967]\n",
      "[0] [64] time: 0:04:41.669773, [d_loss: 0.466562, g_loss: 2.845669]\n",
      "[0] [65] time: 0:04:45.227765, [d_loss: 0.695412, g_loss: 2.282404]\n",
      "[0] [66] time: 0:04:48.694464, [d_loss: 0.541041, g_loss: 3.547473]\n",
      "[0] [67] time: 0:04:52.282782, [d_loss: 0.657189, g_loss: 2.993819]\n",
      "[0] [68] time: 0:04:55.934924, [d_loss: 0.481640, g_loss: 2.795550]\n",
      "[0] [69] time: 0:04:59.567343, [d_loss: 0.699426, g_loss: 2.711810]\n",
      "[0] [70] time: 0:05:03.230448, [d_loss: 0.202765, g_loss: 2.855874]\n",
      "[0] [71] time: 0:05:07.046000, [d_loss: 0.458352, g_loss: 2.234620]\n",
      "[0] [72] time: 0:05:10.801934, [d_loss: 0.420535, g_loss: 2.305719]\n",
      "[0] [73] time: 0:05:14.397059, [d_loss: 0.457632, g_loss: 2.318885]\n",
      "[0] [74] time: 0:05:18.181863, [d_loss: 0.378835, g_loss: 1.977309]\n",
      "[0] [75] time: 0:05:21.957984, [d_loss: 0.587135, g_loss: 2.372880]\n",
      "[0] [76] time: 0:05:25.979399, [d_loss: 0.340721, g_loss: 2.761852]\n"
     ]
    }
   ],
   "source": [
    "train(epochs=700, batch_size=3, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
